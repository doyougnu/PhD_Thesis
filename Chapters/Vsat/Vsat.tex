~\label{chapter:vsat}

This chapter presents the variational satisfiability solving algorithm.
\autoref{sec:approach} provides an overview of the algorithm and introduces the
notion of \emph{variational models} as solutions to variational satisfiability
problems. \autoref{sec:vsat:formalization} provides the formal specification.
\todo{add proofs for confluence and variation preseration}We conclude the
chapter by proving that the variational solving algorithm is confluent and
variation preservation.


\section{General Approach}
\input{Chapters/Vsat/Approach}

\section{Derivation of a Variational Core}
\label{section:vsat:vcore}

A variational core is an IL formula that captures the variational structure of
a query formula. Plain terms will either be placed on the assertion stack or
will be symbolically reduced, leaving only logical connectives, symbolic
references, and choices.

\begin{figure}
  \centering
  % \begin{subfigure}[t]{0.5\textwidth}
    \input{Figures/Vsat_Impl_VCore_Overview}
    \caption{Overview of the reduction engine.}%
    \label{impl:vcore}
  % \end{subfigure}
\end{figure}


The variational core for a \ac{vpl} formula is computed by a reduction engine
illustrated in \autoref{impl:vcore}. The reduction engine has two states:
\emph{evaluation}, which communicates to the base solver to process plain terms,
and \emph{accumulation}, which is called by evaluation to create symbolic
references and reduce plain formulas.


To illustrate how the reduction engine computes a variational core, consider the
query formula $f = ((a \wedge b) \wedge \chc[A]{e_{1}, e_{2}}) \wedge ((p \wedge
\neg q) \vee \chc[B]{e_{3}, e_{4}})$. Translated to an IL formula, $f$ has four
references ($a$, $b$, $p$, $q$) and two choices. The reduction engine will
ultimately produce a variational core that asserts $(a \wedge b)$ in the base
solver, thus pushing it onto the assertion stack, and create a symbolic
reference for $(p \wedge \neg q)$.

Generating the core begins with evaluation. Evaluation matches on the root
$\wedge$ node of $f$ and recurs following the $v_1 \wedge v_2$ edge, where
%
$v_1=(a\wedge b)\wedge\chc[A]{e_1,e_2}$ and
$v_2=(p\wedge \neg q) \vee \chc[B]{e_3, e_4}$.
%
The recursion processes the left child first. Thus, evaluation again matches on
$\wedge$ of $v_{1}$ creating another recursive call with $v_{1}' = (a\wedge b)$
and $v_{2}' = \chc[A]{e_1,e_2}$. Finally, the base case is reached with a final
recursive call where $v_{1}'' = a$, and $v_{2}'' = b$. At the base case, both
$a$ and $b$ are references, so evaluation sends $a$ to the base solver
following the $\kf{r, s, t}$ edge, which returns $\unit{}$ for the left child.
The right child follows the same process yielding $\unit{} \wedge \unit{}$.
Since the assertion stack implicitly conjuncts all assertions, $\unit{} \wedge
\unit{}$ will be further reduced to $\unit{}$ and returned as the result of
$v_{1}'$, indicating that both children have been pushed to the base solver.
This leaves $v_{1}' = \unit{}$ and $v_{2}' = \chc[A]{e_1,e_2}$. $v_{2}'$ is a
base case for choices and cannot be reduced in evaluation, so $\unit{} \wedge
\chc[A]{e_1,e_2}$ will be reduced to just $\chc[A]{e_1,e_2}$ as the result for
$v_{1}$.

In evaluation, conjunctions can be split because of the behavior of the
assertion stack and the and-elimination property of $\wedge$. Disjunctions and
negations cannot be split in this way because both cannot be performed if a
child node has been lost to the solver, e.g., $\neg \unit{}$. Thus, in
accumulation, we construct symbolic terms to represent entire subtrees, which
ensures information is not lost while still allowing for the subtree to be
evaluated if it is sound to do so.

The right child, $v_2=(p\wedge \neg q) \vee \chc[B]{e_3, e_4}$ requires
accumulation. Evaluation will match on the root $\vee$ and send $(p\wedge \neg
q) \vee \chc[B]{e_3, e_4}$ to accumulation via the $v_{1} \vee v_{2}$ edge.
Accumulation has two self-loops, one to create symbolic references (with labels
$r, s, \hdots$), and one to recur to values. Accumulation matches the root
$\vee$ and recurs on the self-loop with edge $v_{1} \vee v_{2}$, where $v_{1} =
(p\wedge \neg q)$ and $v_{2} = \chc[B]{e_3, e_4}$. Processing the left child
first, accumulation will recur again with $v_{1}' = p$ and $v_{2}' = \neg q$.
$v_{1}' = p$ is a base case for references, so a unique symbolic reference
$s_{p}$ is generated for $p$ following the self-loop with label $r$ and
returned as the result for $v_{1}'$. $v_{2}'$ will follow the self-loop with
label $\neg v$ to recur through $\neg$ to $q$, where a symbolic term $s_{q}$
will be generated and returned. This yields $\neg s_{q}$, which follows the
$\neg s$ edge to be processed into a new symbolic term, yielding the result for
$v_{2}'$ as $s_{\neg q}$. With both results $v_{1} = s_{p}\wedge s_{\neg q}$,
accumulation will match on $\wedge$ \emph{and} both $s_{p}$ and $s_{\neg q}$ to
accumulate the entire subtree to a single symbolic term, $s_{pq}$, which will
be returned as the result for $v_{1}$. $v_{2}$ is a base case, so accumulation
will return $s_{pq} \vee \chc[B]{e_3, e_4}$ to evaluation. Evaluation will
conclude with $\chc[A]{e_1,e_2}$ as the result for the left child of $\wedge$
and $s_{pq} \vee \chc[B]{e_3, e_4}$ for the right child, yielding
$\chc[A]{e_1,e_2} \wedge s_{pq} \vee \chc[B]{e_3, e_4}$ as the variational core
of $\kf{f}$.

A variational core is derived to save redundant work.
%
If solved naively, plain sub-formulas of $f$, such as $a \wedge b$ and $p
\wedge \neg q$, would be processed once for each variant even though they are
unchanged. Evaluation moves sub-formulas into the solver state to be reused
among different variants. Accumulation caches sub-formulas that cannot be
immediately evaluated to be evaluated later.


Symbolic references are variables in the reduction engine's memory that
represent a set of statements in the base solver.%
%
\footnote{Note that while we use \acl{smtlib} as an implementation target, any
  solver that exposes an incremental API as defined by
  minisat~\cite{10.1007/978-3-319-09284-3_16} can be used to implement
  variational satisfiability solving.}
%
For example, $s_{pq}$ represents three declarations in the base solver:
%
\begin{lstlisting}[columns=flexible,keepspaces=true,language=SMTLIB]
(declare-const p Bool)
(declare-const q Bool)
(declare-fun $s_{pq}$ () Bool (and p (not q)))
\end{lstlisting}

Similarly a variational core is a sequence of statements in the base solver with
holes $\Diamond$. For example, the variational core of $f$ would be encoded as:
%
\begin{lstlisting}[columns=flexible,keepspaces=true,language=SMTLIB]
(assert (and a b))                 ;; add $a \wedge b$ to the assertion stack
(declare-const $\Diamond$)                   ;; choice A
  (*@\lstvdots@*)                                 ;; potentially many declarations and assertions
(declare-fun $s_{pq}$ () Bool (and p q))  ;;  get symbolic reference for $s_{pq}$
(declare-const $\Diamond$)                   ;; choice B
  (*@\lstvdots@*)                                 ;; potentially many declarations and assertions
(assert (or $s_{ab}$ $\Diamond$))                    ;; assert waiting on $\sem[C]{\chc[B]{e_{3},e_{4}}}$
\end{lstlisting}
%
Each hole is filled by configuring a choice and may require multiple
statements to process the alternative.

\section{Solving the Variational Core}

The reduction engine performs the work at each recursive step whereas the
reification engine defines transitions between the recursive steps by
manipulating the configuration. In \autoref{chapter:vpl}, we formalized
a configuration as a function $D\to\booleans{}$, which we encode in the solver
as a set of tuples $\{\kf{D \times \mathbb{B}}\}$.
%
\autoref{impl:overview} shows two loops for the reification engine corresponding
to the reification of choices. The edges from the reification engine to the
reduction engine are transitions taken after a choice is removed, where new
plain terms have been introduced and thus a new core is derived. If the user
supplied a variation context, then it is used to check that the binding of a
Boolean value to a dimension is valid in the variation context. For example,
$\vc{} = \neg A$ would prevent any configurations where $\kf{(A,\true)} \in C$.
Finally, a model is retrieved from the base solver when the reduction engine
returns \unit{}, indicating that a variant has been reached.

We show the edges of the reification engine relating to the $\wedge$ connective;
the edges for the $\vee$ connective are similar. The left edge is taken when a
choice is observed in the variational core: $v \wedge \sem[C]{\chc[D]{e_{1},
    e_{2}}}$ and $D \in C$. This edge reduces choices with dimension $D$ to an
alternative, which is then translated to IL. The right edge is dashed to
indicate assertion stack manipulation and is taken when $D \notin C$. For this
edge, the configuration is mutated for both alternatives: $C \cup \{(D,
\true)\}$ and $C \cup \{(D, \false)\}$, and the recursive call is wrapped with a
\rn{push} and \rn{pop} command. To the base solver, this branching appears as a
linear sequence of assertion stack manipulations that performs backtracking
behavior. For example, the representation of $\kf{f}$ is:
%
\begin{lstlisting}[columns=flexible,keepspaces=true,language=SMTLIB]
  (*@\lstvdots@*)         ;; declarations and assertions from variational core
(push 1)   ;; a configuration on B has occurred
  (*@\lstvdots@*)         ;; new declarations for left alternative
(declare-fun $s$ () Bool (or $s_{pq}$ $\Diamond[\Diamond \rightarrow s_{B_{T}}]$))  ;; fill
(assert $s$)
  (*@\lstvdots@*)         ;; recursive processing
(pop 1)    ;; return for the right alternative
(push 1)   ;; repeat for right alternative
\end{lstlisting}
%
Where the hole $\Diamond$, will be filled with a newly defined variable
$s_{D_{T}}$ that represents the left alternative's formula.


\section{Variational Models}%
\label{section:vmodels}
%
Classic \ac{sat} models map variables to Boolean values; variational models map
variables to variation contexts that record the variants where the variable was
assigned \tru{}. The variational context for a variable $r$ is denoted as
\vc{r}, and a variational model reserves a special variable called \SatVar{} to
track the configurations that were found satisfiable.
%
\begin{figure}[h]
  \centering
  \input{Figures/Vsat_Impl_plain_models}
  \caption{Possible plain models for variants of $\kf{f}$.}%
  \label{fig:models:plain}
\end{figure}
\begin{figure}[h]
  \centering
  \input{Figures/Vsat_Impl_variational_model}
  \caption{Variational model corresponding to the plain models in
    \autoref{fig:models:plain}.}%
  \label{fig:models:var}
\end{figure}
%
As an example, consider an altered version of the query formula from the
previous section $f = ((\aV{} \wedge \neg \bV{}) \wedge \chc[A]{\aV{}
  \rightarrow \neg \pV{}, \cV{}}) \wedge ((\pV{} \wedge \neg \qV{}) \vee
\chc[B]{\qV{}, \pV{}})$. We can easily see that one variant, with configuration
$\{(\AV{},\tru{}), (\BV{},\fls{})\}$ is unsatisfiable. If the remaining variants
are satisfiable, then three models would result, as illustrated in
\autoref{fig:models:plain}; with the corresponding variational model shown in
\autoref{fig:models:var}.

We see that \Satvc{} consists of three disjuncted terms, one for each
satisfiable variant. Variational models are flexible; a satisfiable assignment
of the query formula can be found by calling \ac{sat} on \Satvc{}. Assuming the
model $C_{FT} = \{(\AV{}, \fls{}), (\BV{}, \tru{})\}$ is returned, one can find
a variable's value through substitution with the configuration; for example,
substituting the returned model on \vc{c} yields:
%
\begin{align*}
  \cV{} \rightarrow\ & (\neg \AV{} \wedge \neg \BV{}) \vee (\neg \AV{} \wedge \BV{}) & \text{\vc{} for \cV{}} \\
  \cV{} \rightarrow\ & (\neg \fls{} \wedge \neg \tru{}) \vee (\neg \fls{} \wedge \tru{}) & \text{Substitute \fls{} for \AV{}, \tru{} for \BV{}} \\
  \cV{} \rightarrow\ & \tru{} & \text{Result}
\end{align*}%
%
Furthermore, finding variants where a variable such as \cV{} is satisfiable is
reduced to $\kf{SAT(\vc{\cV{}})}$

Variational models are constructed incrementally by merging each new plain model
returned by the solver into the variational model. A merge requires the current
configuration, the plain model, and current \vc{} of a variable. Variables are
initialized to \fls{}. For each variable $i$ in the model, if $i$'s assignment
is \tru{} in the plain model, then the configuration is translated to a
variation context and disjuncted with \vc{i}. For example, to merge the
$C_{FT}$'s plain model to the variational model in \autoref{fig:models:var},
$C_{FT}$'s configuration is converted to $\neg \AV{} \wedge \BV{}$. This clause
is disjuncted for variables assigned \tru{} in the plain model: \vc{\aV{}},
\vc{\cV{}}, and \vc{\pV{}}, even if they are new (e.g., \cV{}). Variables
assigned \fls{} are skipped, thus \vc{\qV{}} remains \fls{}. For example, in the
next model $C_{TT}$, \cV{} is \fls{} thus \vc{\cV{}} remains unaltered, while
\vc{\qV{}} flips to \tru{} hence \vc{\qV{}} records $\AV{} \wedge \BV{}$.
Variables such as \bV{}, whose \vc{}'s stay \fls{} are called \textit{constant}.


Variational models are constructed in \ac{dnf}, and form a monoid with $\vee$ as
the semigroup operation, and \fls{} as the unit value. We note this for
mathematically inclined readers and those looking to implement their own
variational solver because it has important ramifications for the asynchronous
version of variational satisfiability solvers.
%
\section{Formalization}
\input{Chapters/Vsat/Formalization}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../thesis"
%%% End:
