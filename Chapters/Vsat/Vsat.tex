~\label{chapter:vsat}

In this section, we present our algorithm for variational satisfiability
solving. \autoref{sec:approach} provides an overview of the algorithm and
introduces the notion of \emph{variational models} as solutions to variational
satisfiability problems. \autoref{sec:formalization} provides the formal
specification.


\section{General Approach}
\label{sec:approach}

\begin{figure}
  \centering
  % \begin{subfigure}[t]{0.5\textwidth}
    \input{Figures/Vsat_Impl_Solve_Overview}
    \caption{System overview of the variational solver.}%
    \label{impl:overview}
  % \end{subfigure}
\end{figure}

We solve \ac{vpl} formulas recursively, decoupling the handling of plain
terms from the handling of variational terms.
%
The intuition behind our algorithm is to first process as many plain terms as
possible (e.g.\ by pushing those terms to the underlying solver) while skipping
choices, yielding a \emph{variational core} that represents only the
variational parts of the original formula. We then alternate between
configuring choices in the variational core and processing the new plain terms
produced by configuration until the entire term has been consumed.
%
Each time the entire term is consumed corresponds to one variant of the
original \ac{vpl} formula since all of its choices will have been configured in a
particular way. At which point, we query the underlying solver to obtain a
model for that variant, then backtrack to solve another variant by configuring
the choices differently. The models for each variant are combined into a single
\emph{variational model} that captures the result of solving all variants of
the original \ac{vpl} formula.


We present an overview of the variational solver as a state diagram in
\autoref{impl:overview} that operates on the input's abstract syntax tree.
Labels on incoming edges denote inputs to a state and labels on outgoing edges
denote return values; we show only inputs for recursive edges; labels separated
by a comma share the edge. We omit labels that can be derived from the logical
properties of connectives, such as commutativity of $\vee$ and $\wedge$.
Similarly, we omit base case edge labels for choices and describe these cases
in the text.

The solver has four subsystems: The \emph{reduction engine} processes plain
terms and generates the variational core, which is ready for reification.
The \emph{reification engine} configures choices in a variational core. The
\textit{base solver} is the incremental solver used to produce plain models.
Finally, the \emph{variational model constructor} synthesizes a single
variational model from the set of plain models returned by the base solver.

The solver takes a \ac{vpl} formula called a \emph{query formula} and an optional
input called a \emph{variation context} (\vc{}). A \vc{} is a propositional
formula of dimensions that restricts the solver to a subset of variants.
%
The variational solver translates the query formula to a formula in an
intermediate language (IL) that the reduction and reification engines operate
over. The syntax of the IL is given below.
%
\[
  v \hquad \Coloneqq\hquad \unit{}
  \hquad|\hquad t
  \hquad|\hquad r
  \hquad|\hquad s
  \hquad|\hquad \neg v
  \hquad|\hquad (v \wedge v)
  \hquad|\hquad v \vee v
  \hquad|\hquad \chc[D]{e,e}
\]
%

The IL includes two kinds of terminals not present in the input query formulas:
plain subterms that can be reduced symbolically will be replaced by a reference
to a \emph{symbolic value} $s$, and subterms that have been sent to the base
solver will be represented by the unit value \unit{}.
%
Note that choices contain unprocessed expressions ($e$) as alternatives.


\paragraph{Derivation of a Variational Core}
\label{ssec:impl:accum}

A variational core is an IL formula that captures the variational structure of
a query formula. Plain terms will either be placed on the assertion stack or
will be symbolically reduced, leaving only logical connectives, symbolic
references, and choices.

\begin{figure}
  \centering
  % \begin{subfigure}[t]{0.5\textwidth}
    \input{Figures/Vsat_Impl_VCore_Overview}
    \caption{Overview of the reduction engine.}%
    \label{impl:vcore}
  % \end{subfigure}
\end{figure}


The variational core for a \ac{vpl} formula is computed by a reduction
engine illustrated in \autoref{impl:vcore}. The reduction engine has two
states: \emph{evaluation}, which communicates to the base solver to process
plain terms, and \emph{accumulation}, which is called by evaluation to create
symbolic references.



To illustrate how the reduction engine computes a variational core, consider the
query formula $f = ((a \wedge b) \wedge \chc[A]{e_{1}, e_{2}}) \wedge ((p \wedge
\neg q) \vee \chc[B]{e_{3}, e_{4}})$. Translated to an IL formula, $f$ has four
references ($a$, $b$, $p$, $q$) and two choices. The reduction engine will
ultimately produce a variational core that asserts $(a \wedge b)$ in the base
solver, thus pushing it onto the assertion stack, and create a symbolic
reference for $(p \wedge \neg q)$.

Generating the core begins with evaluation. Evaluation matches on the root
$\wedge$ node of $f$ and recurs following the $v_1 \wedge v_2$ edge, where
%
$v_1=(a\wedge b)\wedge\chc[A]{e_1,e_2}$ and
$v_2=(p\wedge \neg q) \vee \chc[B]{e_3, e_4}$.
%
The recursion processes the left child first. Thus, evaluation again matches on
$\wedge$ of $v_{1}$ creating another recursive call with $v_{1}' = (a\wedge b)$
and $v_{2}' = \chc[A]{e_1,e_2}$. Finally, the base case is reached with a final
recursive call where $v_{1}'' = a$, and $v_{2}'' = b$. At the base case, both
$a$ and $b$ are references, so evaluation sends $a$ to the base solver
following the $\kf{r, s, t}$ edge, which returns $\unit{}$ for the left child.
The right child follows the same process yielding $\unit{} \wedge \unit{}$.
Since the assertion stack implicitly conjuncts all assertions, $\unit{} \wedge
\unit{}$ will be further reduced to $\unit{}$ and returned as the result of
$v_{1}'$, indicating that both children have been pushed to the base solver.
This leaves $v_{1}' = \unit{}$ and $v_{2}' = \chc[A]{e_1,e_2}$. $v_{2}'$ is a
base case for choices and cannot be reduced in evaluation, so $\unit{} \wedge
\chc[A]{e_1,e_2}$ will be reduced to just $\chc[A]{e_1,e_2}$ as the result for
$v_{1}$.

In evaluation, conjunctions can be split because of the behavior of the
assertion stack and the and-elimination property of $\wedge$. Disjunctions and
negations cannot be split in this way because both cannot be performed if a
child node has been lost to the solver, e.g., $\neg \unit{}$. Thus, in
accumulation, we construct symbolic terms to represent entire subtrees, which
ensures information is not lost while still allowing for the subtree to be
evaluated if it is sound to do so.

The right child, $v_2=(p\wedge \neg q) \vee \chc[B]{e_3, e_4}$ requires
accumulation. Evaluation will match on the root $\vee$ and send $(p\wedge \neg
q) \vee \chc[B]{e_3, e_4}$ to accumulation via the $v_{1} \vee v_{2}$ edge.
Accumulation has two self-loops, one to create symbolic references (with labels
$r, s, \hdots$), and one to recur to values. Accumulation matches the root
$\vee$ and recurs on the self-loop with edge $v_{1} \vee v_{2}$, where $v_{1} =
(p\wedge \neg q)$ and $v_{2} = \chc[B]{e_3, e_4}$. Processing the left child
first, accumulation will recur again with $v_{1}' = p$ and $v_{2}' = \neg q$.
$v_{1}' = p$ is a base case for references, so a unique symbolic reference
$s_{p}$ is generated for $p$ following the self-loop with label $r$ and
returned as the result for $v_{1}'$. $v_{2}'$ will follow the self-loop with
label $\neg v$ to recur through $\neg$ to $q$, where a symbolic term $s_{q}$
will be generated and returned. This yields $\neg s_{q}$, which follows the
$\neg s$ edge to be processed into a new symbolic term, yielding the result for
$v_{2}'$ as $s_{\neg q}$. With both results $v_{1} = s_{p}\wedge s_{\neg q}$,
accumulation will match on $\wedge$ \emph{and} both $s_{p}$ and $s_{\neg q}$ to
accumulate the entire subtree to a single symbolic term, $s_{pq}$, which will
be returned as the result for $v_{1}$. $v_{2}$ is a base case, so accumulation
will return $s_{pq} \vee \chc[B]{e_3, e_4}$ to evaluation. Evaluation will
conclude with $\chc[A]{e_1,e_2}$ as the result for the left child of $\wedge$
and $s_{pq} \vee \chc[B]{e_3, e_4}$ for the right child, yielding
$\chc[A]{e_1,e_2} \wedge s_{pq} \vee \chc[B]{e_3, e_4}$ as the variational core
of $\kf{f}$.

A variational core is derived to save redundant work.
%
If solved naively, plain sub-formulas of $f$, such as $a \wedge b$ and $p
\wedge \neg q$, would be processed once for each variant even though they are
unchanged. Evaluation moves sub-formulas into the solver state to be reused
among different variants. Accumulation caches sub-formulas that cannot be
immediately evaluated to be evaluated later.


Symbolic references are variables in the reduction engine's memory that
represent a set of statements in the base solver.%
%
\footnote{In this section, we use SMTLIB2 snippets to represent operations
performed on the base solver. While we target SMTLIB2, conforming to the
standard is not a requirement. Any solver that exposes an incremental API as
defined by minisat~\cite{10.1007/978-3-319-09284-3_16} can be used to implement
variational satisfiability solving.}
%
For example, $s_{pq}$ represents three declarations in the base solver:
%
\begin{lstlisting}[columns=flexible,keepspaces=true]
(declare-const p Bool)
(declare-const q Bool)
(declare-fun $s_{pq}$ () Bool (and p (not q)))
\end{lstlisting}

Similarly a variational core is a sequence of statements in the base solver with
holes $\Diamond$. For example, the variational core of $f$ would be encoded as:
%
\begin{lstlisting}[columns=flexible,keepspaces=true]
(assert (and a b))                 ;; add $a \wedge b$ to the assertion stack
(declare-const $\Diamond$)                   ;; choice A
  (*@\lstvdots@*)                                 ;; potentially many declarations and assertions
(declare-fun $s_{pq}$ () Bool (and p q))  ;;  get symbolic reference for $s_{pq}$
(declare-const $\Diamond$)                   ;; choice B
  (*@\lstvdots@*)                                 ;; potentially many declarations and assertions
(assert (or $s_{ab}$ $\Diamond$))                    ;; assert waiting on $\sem[C]{\chc[B]{e_{3},e_{4}}}$
\end{lstlisting}
%
Each hole is filled by configuring a choice and may require multiple
statements to process the alternative.

\paragraph{Solving the Variational Core}

The reduction engine performs the work at each recursive step whereas the
reification engine defines transitions between the recursive steps by
manipulating the configuration. In \autoref{sec:vlogic}, we formalized
a configuration as a function $D\to\mathbb{B}$, which we encode in the solver
as a set of tuples $\{\kf{D \times \mathbb{B}}\}$.
%
\autoref{impl:overview} shows two self-loops for the reification engine
corresponding to the reification of choices. The edges from the reification
engine to the reduction engine are transitions taken after a choice is removed,
where new plain terms have been introduced and thus a new core is derived. If
the user supplied a variation context, then it is used to construct an initial
configuration. Finally, a model is retrieved from the base solver when the
reduction engine returns \unit{}, indicating that a variant has been reached.

We show the edges of the reification engine relating to the $\wedge$
connective; the edges for the $\vee$ connective are similar.
The left edge is taken when a choice is observed in
the variational core: $v \wedge \sem[C]{\chc[D]{e_{1}, e_{2}}}$ and $D \in C$.
This edge reduces choices with dimension $D$ to an alternative, which is then
translated to IL. The right edge is dashed to indicate assertion stack
manipulation and is taken when $D \notin C$. For this edge, the configuration
is mutated for both alternatives: $C \cup \{(D, \tru{})\}$ and $C \cup \{(D,
\fls{})\}$, and the recursive call is wrapped with a \texttt{push} and
\texttt{pop} command. To the base solver, this branching appears as a linear
sequence of assertion stack manipulations that performs backtracking behavior.
For example, the representation of $\kf{f}$ is:
%
\begin{lstlisting}[columns=flexible,keepspaces=true]
  (*@\lstvdots@*)         ;; declarations and assertions from variational core
(push 1)   ;; a configuration on B has occurred
  (*@\lstvdots@*)         ;; new declarations for left alternative
(declare-fun $s$ () Bool (or $s_{pq}$ $\Diamond[\Diamond \rightarrow s_{B_{T}}]$))  ;; fill
(assert $s$)
  (*@\lstvdots@*)         ;; recursive processing
(pop 1)    ;; return for the right alternative
(push 1)   ;; repeat for right alternative
\end{lstlisting}
%
Where the hole $\Diamond$, will be filled with a newly defined variable
$s_{D_{T}}$ that represents the left alternative's formula.

\paragraph{Variational Models}%
\label{ssec:vmodels}
%
Plain models map variables to Boolean values; variational models map variables
to variation contexts that record the variants where the variable was assigned
\tru{}. We denote the variation context for a variable $r$ as \vc{r}, and
maintain a special variable called \SatVar{} to track which configurations are
satisfiable.

\begin{figure}
  \input{Figures/Vsat_Impl_plain_models}
  \vspace{-2ex}
  \caption{Possible plain models for variants of $f_{\text{\FM{02}}}$.}%
  \label{fig:models:plain}
\end{figure}

\begin{figure}
  \input{Figures/Vsat_Impl_variational_model}
  \caption{Variational model of the plain models in \autoref{fig:models:plain}.}%
  \label{fig:models:var}
\end{figure}


For example, consider the query formula $f_{\text{\FM{012}}}$ from the
Linux example in \autoref{sec:bkgrnd}.
If each variant is satisfiable, there are three models, as illustrated in
\autoref{fig:models:plain}. The corresponding variational model is shown in
\autoref{fig:models:var}.
The variation context for \SatVar{}, \Satfmf{}, consists of three
disjuncted terms, one
for each satisfiable variant. A satisfiable assignment of the query
formula can be found by calling \ac{sat} on \Satfmf{}. Assuming the model $C_{FT} =
\{(\LOne{}, \fls{}), (\LTwo{}, \tru{})\}$ is returned, substitution on
\vc{f_{i}} yields $f_{i}$'s value in $C_{FT}$:
%
\begin{align*}
  f_{i} \rightarrow\ & (\neg \LOne{} \wedge \LTwo{}) & \text{\vc{} for $f_{i}$} \\
  f_{i} \rightarrow\ & (\neg \fls{} \wedge \tru{}) & \text{Substitute \fls{} for \LOne{}, \tru{} for \LTwo{}} \\
  f_{i} \rightarrow\ & \tru{} & \text{Result}
\end{align*}%
%
Additionally, we can compute all variants where a variable $f_j$ is
satisfiable by solving $\kf{SAT(\vc{f_j})}$

Variational models are constructed incrementally by merging each new plain model
returned by the solver into the variational model. A merge requires the current
configuration, the plain model, and the current \vc{} of a variable. Variables are
initialized to \fls{}. For each variable $i$ in the model, if $i$'s assignment
is \tru{} in the plain model, then the configuration is translated to a
variation context and disjuncted with \vc{i}. For example, to merge the
$C_{FT}$'s plain model to the variational model in \autoref{fig:models:var},
$C_{FT}$'s configuration is converted to $\neg \LOne{} \wedge \LTwo{}$. This
clause is disjuncted with the current \vc{} for in the variational model
for all of the variables assigned \tru{} in the plain model: \vc{0},
\vc{i}, and \vc{\mathit{mitigations}}, even if they are new (e.g.,
$\kf{mitigations}$). Variables assigned \fls{} are skipped, thus \vc{n} remains
\fls{}. In the next model $C_{TT}$, $f_{i}$ is \fls{} so \vc{i} remains
unaltered. Variables such as $f_{n}$, whose \vc{} remains \fls{}, are called
\textit{constant}.

\section{Formalization}
\input{Chapters/Vsat/Formalization}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../thesis"
%%% End:
