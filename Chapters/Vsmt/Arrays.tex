\label{section:vsmt:arrays}
%
With variational \ac{smt} solving fully specified we can reflect on the
generalization recipe from the previous sections. Say we desired to add the
\ac{smt} background for \rn{Reals}. Doing so would follow the straightforward
recipe demonstrated with \rn{Ints}: From the \acl{smtlib} standard we have a set
of primitive operators, we would define wrapped primitive versions for each
operator. Using these wrapped operators we would define new cases for
accumulation and a base case for evaluation indicating that the new operator
requires accumulation. Then we would add the new domain to the syntactic
categories in \autoref{fig:vsmt:categories}. Choice removal would be extended
with three new rules, a rule to begin the processing of the left child of the
relation, a rule to switch from the left child to the right only when a symbolic
value is in the focus, and a rule that performs the fold by combining two
symbolic values and thus consuming some of the context.

In essence, we have a recipe for a generalized variational folding algorithm
over binary relations, that forces reuse of shared terms and is applied to the
domain of \ac{sat} and \ac{smt} solvers. Recall that a symbolic value is a
sequence of statements in the base solver. Thus, another way to view our
generalized folding algorithm is as a compiler from the language of variational
\ac{sat} or \ac{smt} to plain \acl{smtlib} script. The stages of the compiler in
this interpretation are straightforward: We parse a variational \ac{sat} or
\ac{smt} problem to a abstract syntax tree in an intermediate language. The
intermediate language enables optimization passes and is easier to work with
than the object language. Accumulation and evaluation produce a variational core
which can be seen as another, further reduced core language, or as a syntax
object which encapsulates the variational aspects of the input. The core
language is then operated upon by choice removal which deterministically
produces the variant syntax objects. Code generation is spread across generation
of symbolic values in accumulation, assertion of constraints in evaluation, and
calls to \rn{push} or \rn{pop} during choice removal, specifically during
\crChc.

The exact ordering of the operations in the base solver, or the ordering of code
generation, is implementation specific. In the prototype solvers that we have
produced and will discuss further in the next chapter, code generation that
corresponds to generating symbolic values occurs when the symbolic value becomes
known to \aStore. When a configuration occurs the \rn{push}/\rn{pop} calls
encapsulate the operator the choice was nested in and any new symbolic values
which result from the configuration. This ensures sharing of terms that are in
the same assertion levels. For example, consider the case of $s_{12}$ from
\autoref{section:vsmt:example}, $s_{12}$ will be shared once for each variant
because it is plain, thus the code which defines it must occur \emph{before} a
\rn{push} and \rn{pop} call:
%
\begin{lstlisting}[columns=flexible,keepspaces=true,language=SMTLIB]
(declare-const $s_{1}$ Int)           ;; literal declarations
(declare-const $s_{2}$ Int)
(declare-fun $s_{12}$ () Int
  (+ $s_{1}$ $s_{2}$))
(push)                         ;; push for true alternative of $A$
$\vdots{}$
\end{lstlisting}
%
Similarly for terms such as $s_{ik}$ which will be shared twice but are not
plain; because $i$ was transformed into a symbolic before the choice was
configured its declaration still occurs outside the \rn{push}/\rn{pop} block. In
contrast, $k$ is parameterized by a choice and thus its declaration occurs
inside a \rn{push}/\rn{pop} block:
%
\begin{lstlisting}[columns=flexible,keepspaces=true,language=SMTLIB,breaklines=true]
(declare-const $s_{1}$ Int)         ;; literal declarations
(declare-const $s_{2}$ Int)
(declare-fun $s_{12}$ () Int
  (+ $s_{1}$ $s_{2}$))
$\vdots{}$
(declare-const $s_{i}$ Int)           ;; i is declared
(push)                         ;; push for true alternative of A
(declare-const $s_{k}$ Int)
(declare-fun $s_{ik}$ () Int
  (< $s_{i}$ $s_{k}$))
$\vdots{}$
\end{lstlisting}
%
In this case the ordering of symbolic value generation forced $s_{k}$ to be
inside the \rn{push} call so that it is removed from the local scope of the
solver after a \rn{pop} and thus the boundaries between alternatives do not leak
information. Notice that the inference rules in
\autoref{section:vsmt:accumulation}, \autoref{section:vsmt:evaluation} and
\autoref{section:vsmt:choice-removal} guarantee this behavior because symbolic
value creation is ordered according to levels of variation. For example, plain
terms are level 0 as no configuration has happened. In a sense they are globally
scoped and thus become symbolic values or \unit{}'s first. It is only after a
configuration occurs from \crChc{} that more plain terms are introduced. When a
configuration occurs a new \rn{push}/\rn{pop} block is entered, and thus any
calls to accumulation which occur inside it occur inside that block in the base
solver and correspond to level 1. Furthermore, the level is propagated by the $D
\in \configuration$ check in \crChcT{} and \crChcF{}.

To demonstrate the generality of this design we now consider the case of adding
\ac{smt} arrays. To add \ac{smt} arrays we treat arrays as a new kind of
relation. By treating them like any other relation, we take advantage of the
aforementioned ordering behavior and offload the hard work to choice removal.
\ac{smt} arrays are defined by two operations \store*{a}{i}{e} and
\select*{a}{i}, where $a$ is a variable representing the array, $i$ is an index
into the array, and $e$ is an element of the array. Each operation must exist
inside a boolean constraint to propagate information about the array, for
example $\store*{a}{2}{b}$ leaves $a$ unconstrained, while $a \equiv
\store*{a}{2}{b}$ adds a constraint that forces position 2 to store $b$ in $a$.
Similarly, \select{} must exist in a constraint, \eg{}, $x \equiv
\select*{a}{2}$ will add a constraint which sets $x$ to $b$.

Assume that we restrict $i$ to only \rn{Int}, using the recipe above we would
wrap these operations, add new rules to accumulation to accumulate anything in
the $a$, $i$, or $e$ positions and then extend \zipper{} such that a context
could be captured wherever choices may occur. For example we might have:
%
\begin{figure}
  \centering
  \begin{syntax}
    \zipper & \Coloneqq{} & \inRoot  \\
    & | & \inNot{\zipper}            \\
    & | & \inUnary{\zipper}          \\
    & | & \inBoolL{\zipper}{\,\eIL}   \\
    & | & \inBoolR{s}{\zipper}       \\
    & | & \inArithL{\zipper}{\,\eIL}  \\
    & | & \inArithR{s}{\zipper}      \\
    & | & \inInEqL{\zipper}{\,\eIL}   \\
    & | & \inInEqR{s}{\zipper}       \\
    & | & \inSelectL{s}{s}{\zipper} \\
    & | & \inSelectM{s}{s}{\zipper} \\
    & | & \inSelectR{s}{s}{\zipper} \\
    & | & \inStoreL{s}{\zipper} \\
    & | & \inStoreR{s}{\zipper} \\
  \end{syntax}
\end{figure}
%
Which is verbose but would work. Now consider a formula which contains a nested
choice in an arithmetic expression in the element slot of \select{} but not
store: $\kf{f} = (a \equiv \store*{a}{2}{(i - \chc[A]{k,l})}) \wedge (i \equiv
\select{a}{2}) \wedge (i \equiv l)$. The conjunctions indicate separate
statements in \acl{smtlib} due to the behavior of the assertion stack. The
formula is noteworthy because both the \select{} and $i \equiv l$ call are plain
and thus will be processed by evaluation/accumulation \emph{before} choice
removal via the \evAndL{} and \evAndR. This may seem problematic as calling a
\select{} before a \store{} in other paradigms would lead to an error. However
this will not be the case, consider the compiled \acl{smtlib} script for $f$:
%
\begin{lstlisting}[columns=flexible,keepspaces=true,language=SMTLIB,breaklines=true]
(declare-const $s_{a}$ (Array Int Int))         ;; variable declarations
(declare-const $s_{i}$ Int)
(declare-const $s_{l}$ Int)
(declare-const $s_{2}$ Int)
(declare-fun $s_{sel}$ () Int                    ;; select
  (= $s_{i}$ (select $s_{a}$ $s_{2}$)))
(declare-fun $s_{il}$ () Int                    ;; equivalency constraint
  (= $s_{i}$ $s_{l}$))
(assert $s_{sel}$)
(assert $s_{il}$)
(push)                                  ;; push for true alternative of A
(declare-const $s_{k}$ Int)
(declare-fun $s_{ik}$ () Int
  (- $s_{i}$ $s_{k}$))
(assert (= $s_{a}$ (store $s_{a}$ ($s_{2}$) ($s_{ik}$)))
(check-sat)
(get-model)                             ;; plain model for true alternative
(pop)
(push)                                  ;; push for false alternative of A
(declare-fun $s_{il}$ () Int
  (- $s_{i}$ $s_{l}$))
(assert (= $s_{a}$ (store $s_{a}$ ($s_{2}$) ($s_{il}$)))
(check-sat)
(get-model)                             ;; plain model for false alternative
(pop)
\end{lstlisting}
%
We see that evaluation/accumulation did find the plain \select{} and $i \equiv
l$ constraints and assert them before the choice is processed. However, because
constraints in the base solver can be unordered---due to the implicit
conjunction of all assertions in an assertion level---the out of order \select{}
and constraint $i \equiv l$ are not problematic. Furthermore, we see that the
\acl{smtlib} snippet has desirable properties: every plain or variational term
that can be shared, such as $l$ and $i$, is shared. When a \rn{push}/\rn{pop}
block is entered the block is as small as possible, thus sharing is maximized as
much as possible. Due to the symbolic values generated by
accumulation/evaluation, variation does not spread past the immediate relation
and thus other relations do not suffer from \todo{find a
  reference or cite kleene}\emph{variational infection}.

We have demonstrated the generality of our approach by extensions with the
differing domains of arithmetic over integers and arrays. Key to the approach is
the indirection with symbolic values, and the use of a zipper to construct a
generalized variational folding algorithm over any unary, binary, or ternary
relation. Thus, with just what has been presented here we can support the rest
of the core theories in \acl{smtlib} using the aforementioned extension recipe.
We return to this point in \autoref{chapter:related-work} when we discuss the
implications for a variational logic programming language.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../thesis"
%%% End: